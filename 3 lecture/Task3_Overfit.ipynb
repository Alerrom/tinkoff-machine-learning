{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML T-Generation Занятие 3: Линейная регрессия.\n",
    "# Проблема переобучения. Кросс-валидация и регуляризация.\n",
    "\n",
    "Авторы: Гаркавый Андрей (andrewgarkavyy@gmail.com), Кирилл Васильев (kirivasile@yandex.ru)\n",
    "\n",
    "\n",
    "## 0. План\n",
    "\n",
    "1. Приближение одномерной функции многочленом\n",
    "\n",
    "2. Переобучение\n",
    "\n",
    "3. Выводы\n",
    "\n",
    "4. Разделение на тренировочную и тестовую части\n",
    "\n",
    "5. Кросс-валидация\n",
    "\n",
    "6. Линейная регрессия\n",
    "\n",
    "7. Как подбираются коэффициенты\n",
    "\n",
    "8. Регуляризация\n",
    "\n",
    "## 1. Приближение одномерной функции многочленом\n",
    "\n",
    "Начнем с простой задачи.\n",
    "\n",
    "\n",
    "1) Есть функция $f(x)$, но мы ее не знаем.\n",
    "\n",
    "2) Зато мы знаем ее значения в $m$ точках (они называются тренировочным множеством):\n",
    "$$f(x_1) = y_1$$\n",
    "$$\\cdots$$\n",
    "$$f(x_m) = y_m$$\n",
    "3) Нужно научиться приблизительно восстанавливать эту функцию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ - научиться приближать её многочленом, а именно давайте подберем такие коэффициенты $a_0, a_1, \\ldots, a_n$, чтобы многочлен $P(x) = a_0 + a_1x + a_2x^2 + \\ldots + a_nx^n$ был как можно ближе к $f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но что такое \"приблизить\"? Мы знаем лишь значения в $m$ точках, так что в лучшем случае она должна проходить через все эти точки (хотя скоро мы увидим, что это не так)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом случае обычно пытаются минимизировать сумму квадратов ошибок во всех точках, то есть **функцию потерь** $$L(P) = \\sum_i (P(x_i) - f(x_i))^2 $$\n",
    "\n",
    "Эту величину называют **MSE** - Mean Squared Error (средняя квадратичная ошибка)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут может возникнуть вопрос, почему мы берем именно сумму квадратов, а не, например, сумму модулей. Однозначного ответа на этот вопрос нет, наиболее удачный ответ, пожалуй такой: у суммы квадратов есть много удобных свойств, например это выпуклая, дифференцируемая функция. Тем не менее иногда другой выбор может быть оправданным. Если вам интересно чуть больше понять про смысл этих условий, можете решить такие задачи:\n",
    "\n",
    "**(0.5 балла) Доп. Задача 1.** Найдите число m такое, что для заданных $x_i$ сумма $\\sum|m - x_i|$ минимальна\n",
    "\n",
    "<Место для решения>\n",
    "\n",
    "**(0.5 балла) Доп. Задача 2.** Найдите число m такое, что для заданных $x_i$ сумма $\\sum(m - x_i)^2$ минимальна\n",
    "\n",
    "\n",
    "<место для решения>\n",
    "\n",
    "Сейчас можно их и пропустить.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В питоне есть пакет scipy, в котором как раз есть решение этой задаче - подбор такого многочлена для заданных точек, что среднеквадратичная ошибка минимальна.\n",
    "\n",
    "Чтобы им пользоваться, вам нужно ввести в консоли Анаконды `conda install scipy`. Или, если вы настроили pip `pip install scipy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала просто нарисуем какой-нибудь многочлен, например $f(x) = 3x^3 - 2x^2 + x$ на отрезке $[-1, 1]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 3 * x ** 3 - 2 * x**2 + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x100 = np.linspace(-1, 1, 100)\n",
    "plt.plot(x100, f(x100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь зададим набор точек (10 штук) и посмотрим что будет, если подобрать по ним коэффициенты нашего многочлена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 10)  # 10 точек на отрезке [-1, 1]\n",
    "y = f(x)\n",
    "coefs = np.polyfit(x, y, deg = 2)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(это означает многочлен $-2x^2 + 3.17037 x$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scipy позволяет легко работать с многочленами, заданными их коэффициентами. Мы можем создать из них объект poly1d, который можно будет просто вызывать для получения нужных значений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = np.poly1d(coefs)\n",
    "poly(0), poly(1), poly(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(x100, f(x100))\n",
    "plt.plot(x100, poly(x100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Довольно ожидаемо, наша функция (оранжевая) не очень похожа на то, что мы искали (синяя). Наверное зря мы пытаемся приблизить кубическую функцию многочленом второй степени. Давайте попробуем 3-ю степень."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = np.polyfit(x, y, deg = 3)\n",
    "poly = np.poly1d(coefs)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x100, f(x100))\n",
    "plt.plot(x100, poly(x100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этот раз мы в точности угадали функцию. Можете проверить, что если увеличивать степень многочлена, результат не меняется: более высокие степени тут просто не нужны.\n",
    "\n",
    "Но мы сейчас жили в идеальном мире. На практике чаще всего известные нам значения не совсем точны. Давайте добавим к значениям нашей функции немного шума:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 10)\n",
    "y = f(x) + np.random.normal(0, 0.5, 10)  # случайный шум"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = np.polyfit(x, y, deg = 3)\n",
    "poly = np.poly1d(coefs)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x100, f(x100))\n",
    "plt.plot(x100, poly(x100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы почти попали. Перед тем как читать дальше, подумайте над заданием.\n",
    "\n",
    "**(1 балл) Обязательное задание 1:** попробуйте увеличить степень полинома. Что произойдет с графиком нашего приближения? Посмотрите  как обе функции себя ведут вне интервала x. Попробуйте сформулировать проблему, с которой мы столкнулись."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Место для решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Переобучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То, что вы увидели при решении этого задания называется в машинном обучении **переобучением** (overfittig).\n",
    "\n",
    "Если мы используем достаточно сложную модель (то есть модель, у которой много параметров, в нашем случае -- многочлен достаточно высокой степени), то у модели появляется возможность \"выучить\" все точки, которые она видела. Например, если задано $m$ точек, всегда можно подобрать многочлен степени $m-1$, который через них проходит (если вы не знакомы с этим фактом, можете подумать, как его доказать).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Честный\" способ проверять качество нашей апроксимации -- **смотреть точность в точках, которые мы не использовали при подборе многочлена**. Это множество часто называют тестовым множеством. Давайте зададим его так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возьмем 10 случайных точек от 0 до 1\n",
    "x_test = np.random.random(10) \n",
    "\n",
    "# превратим их в 10 случайных точек от -1 до 1\n",
    "x_test = 2 * x_test - 1\n",
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл)  Обязательное задание 2:** напишите функцию, которая для данного многочлена считает его качество на тестовом множестве (то есть среднеквадратичное отклонение между значениями функции $f$ и многочлена $P$ на тестовой выборке).\n",
    "\n",
    "Вы все прошлое занятие изучали разные функции, попробуйте сделать MSE как можно более компактной функцией (желательно в одну строчку)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_real - это np.array c реальными значениями в точках\n",
    "# y_pred - это np.array c предсказанными нами значениями в точках\n",
    "# они одной длины\n",
    "def MSE(y_real, y_pred):\n",
    "    pass  # реализуйте функцию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл) Обязательное задание 3:** нарисуйте график зависимости ошибки на тестовом множестве от степени многочлена. При какой степени ошибка минимальна?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# место для решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл) Доп. задача 5:** как меняется график, если увеличивать количество точек в множестве, на котором мы подбираем многочлен?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# место для решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Выводы\n",
    "\n",
    "1) Цель машинного обучения с учителем - приблизить **целевую функцию** (target) по её значениям (возможно приблзительным) в некоторых точках.\n",
    "\n",
    "В нашем случае - это $f(x) = 3x^3 - 2x^2 + x$. Обычно она, конечно, никому неизвестна.\n",
    "\n",
    "2) Множество точек с известным значением функции называется **тренировочным множеством** (train).\n",
    "\n",
    "В нашем случае - это 10 точек, выбранных равномерно на отрезке $[-1, 1]$.\n",
    "\n",
    "3) Чтобы приблизить функцию, нужно использовать какую-то **модель** (model), приближающую функцию.\n",
    "\n",
    "В данном случае - это многочлен $P(x) = a_0 + a_1x + a_2x^2 + \\ldots + a_nx^n$.\n",
    "\n",
    "4) Мы выбираем **функцию потерь** (loss function) для сравнения результатов модели и реальных значения на тренировочном множестве. Чем она меньше, тем лучше наша модель.\n",
    "\n",
    "В данном случае - это $MSE = \\sum_i (P(x_i) - f(x_i))^2$.\n",
    "\n",
    "5) У модели есть **параметры**, которые мы выбираем так, чтобы функция потерь на тренировочном множестве была минимальна.\n",
    "\n",
    "В данном случае - это коэффициенты многочлена ($a_0, a_1, \\ldots, a_n$). Выбираются они с помощью пока магической для нас функции polyfit.\n",
    "\n",
    "6) У модели есть **гиперпараметры**, которые мы выбираем сами.\n",
    "\n",
    "В данном случае - это степень многочлена (число $n$).\n",
    "\n",
    "7) Однако такой подход с минимизацией функции потерь может привести к тому, что мы идеально приблизим функцию на тренировочном множестве, но она будет абсолютно отличаться во всех остальных точках. Это явление называется **переобучением**.\n",
    "\n",
    "В данном случае - мы видели, что если степень многочлена большая (больше трех), то мы попадаем во все точки, но при этом сам многочлен сильно отличается от $f(x)$.\n",
    "\n",
    "8) Чтобы бороться с переобучением, полезно выделить **тестовое множество** точек, в которых мы тоже знаем результаты функции. Оно никак не используется при обучении модели, и нужно только для валидации результата.\n",
    "\n",
    "В данном случае - мы взяли рандомные 10 точек на отрезке $[-1, 1]$.\n",
    "\n",
    "9) В идеальном случае функция потерь на тренировочном и тестовом множестве не отличается. А вот если на тренировочном функция потерь получается гораздо меньше, чем на тестовом, то это говорит о том, что происходит переобучение.\n",
    "\n",
    "Действительно, при большой степени MSE близка к или равна нулю на тренировочном множестве, а на тестовом множестве нет.\n",
    "\n",
    "10) Единственный пока способ, который мы знаем, чтобы влиять на переобучение - это перебирать **гиперпараметры** модели так, чтобы **минимизировать функцию потерь на тестовом множестве**.\n",
    "\n",
    "Действительно, если выбрать степень 3, то функция потерь окажется минимальной на тестовом множестве, как мы видели в задании 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Разделение на тренировочную и тестовую части"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы решите поучаствовать в каком-нибудь соревновании по машинному обучению, вы увидите, что тестовое множество вам недоступно (иначе было бы неинтересно: очень легко обучиться предсказывать то, что ты уже видел).\n",
    "\n",
    "В реальной жизни обычно тоже считают, что на тестовом множестве можно провериться один раз -- в самом конце. Иначе вы начнете подкручивать гиперпараметры глядя на результат на тестовой выборке и, сами того не замечая, переобучитесь.\n",
    "\n",
    "Как поступать в такой ситуации? Придется пожертвовать частью точек, которые даны нам для обучения и использовать их для подбора гиперпараметров в нашем алгоритме (в нашем случае это степень многочлена).\n",
    "\n",
    "То есть придется из точек, у которых мы знаем результаты, убрать, например, 10% в тестовое множество.\n",
    "\n",
    "Функция для этого есть, например, в пакете sklearn, который можно скачать так: `pip install scikit-learn` (`conda install scikit-learn`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-1, 1, 50)\n",
    "y = f(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Кросс-валидация\n",
    "\n",
    "Также есть более точный способ проводить валидацию результата. Если разделить множество один раз на тестовое и тренировочное, то это может значительно влиять на результат. Вдруг в тестовое множество случайно попали такие точки, в которых предсказать значение тяжелее или легче, чем обычно?\n",
    "\n",
    "Тогда можно применить **кросс-валидацию** - давайте разделим множество на 10 примерно равных частей, тогда у нас есть 10 разделений на тренировочное и тестовое множество - как тестовое множество выберем по очереди каждую из этих частей, а как тренировочное выберем все остальные части. В итоге, все элементы множества побывают и в тренировочной, и в тестовой чати.\n",
    "\n",
    "Можно посчитать результат на каждом из 10 разбиений и просто усреднить результат.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Есть вот такая удобная штука\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(test_index, train_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл) Доп. задача 6:** проделайте все вышеописанное с функцией $f(x) = \\frac{1}{1 + e^{-x}}$ на отрезке $[-3, 3]$. Как оптимальная степень зависит от количества точек, по которым вы подбираете многочлен?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# место для решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Линейная регрессия\n",
    "\n",
    "**Регрессией** называется задача машинного обучения с учителем, в которой у нас есть много объектов с признаками, у которых надо научиться приближенно предсказывать значение целевой функции, которая равна какому-то **действительному числу**. \n",
    "\n",
    "В этом будет отличие задачи регрессии от задачи классификации - регрессия предсказывает число, а классификация - один из нескольких классов.\n",
    "\n",
    "До этого мы учились приближать одномерную функцию многочленом. Каждая точка имела ровно один признак - коодинату $x$.\n",
    "\n",
    "Тем не менее, чаще всего в машинном обучении признаков гораздо больше. Возьмем какой-нибудь реальный датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('Advertising.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете показаны результаты продаж разных товаров в зависимости от ресурсов (тысяч долларов), которые вложили в различные средства распространения информации:\n",
    "* TV - реклама по телевизору\n",
    "* radio - на радио\n",
    "* newspapers - в газетах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевая переменная:\n",
    "\n",
    "sales - продажи такого-то товара (тысячи штук)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Размеры датасета\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаков немного, поэтому давайте попробуем визуализиовать зависимость целевой переменной от каждого из признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, sharey=True)\n",
    "data.plot(kind='scatter', x='TV', y='Sales', ax=axs[0], figsize=(16, 8))\n",
    "data.plot(kind='scatter', x='Radio', y='Sales', ax=axs[1])\n",
    "data.plot(kind='scatter', x='Newspaper', y='Sales', ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простая линейная регрессия\n",
    "\n",
    "Из графиков выше предположим, что только размер рекламы на телевизоре влияет на продажи больше всего. Формула для такого случая выглядит следующим образом:\n",
    "$$y=\\beta_0+\\beta_1x$$\n",
    "Здесь:\n",
    "* $y$ - наше предсказание продаж\n",
    "* $x$ - сколько денег вложили в рекламу по телевидению\n",
    "* $\\beta_0$ - сдвиг\n",
    "* $\\beta_1$ - параметр, отвечающий за важность признака x\n",
    "\n",
    "$\\beta_0$ и $\\beta_1$ - это параметры нашей модели. Чтобы создать хорошую модель, надо \"обучить\" эти значения. Т.е. изменить их так, чтобы они хорошо работали для нашей задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение коэффициентов модели\n",
    "\n",
    "Параметры $\\beta_0$ и $\\beta_1$ подбираются таким образом, чтобы минимизировать **сумму наименьших квадратов ошибок**:\n",
    "\n",
    "$$L(MSE)=\\sum_{i=1}^{N}(y^{true}_i-y^{pred}_i)^2$$\n",
    "\n",
    "<img src=\"mse_plot.png\">\n",
    "\n",
    "* Чёрные точки на даграмме $y^{true}$ - это полученные истинные значения x и y .\n",
    "* Синяя линия $y^{pred}$ - это наша модель: линия, которой мы стараемся приблизить данные .\n",
    "* Красные отрезки - это ошибки нашей модели.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как коэффициенты $\\beta_0$ и $\\beta_1$ соотносятся с синей линией:\n",
    "* $\\beta_0$ - это сдвиг нашей прямой, т.е. значение y при x = 0.\n",
    "* $\\beta_1$ - это тангенс угла наклона прямой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как искать данные коэффициенты? Есть много техник: аналитическое решение, методы основанные на градиентном спуске. Пока же достаточно знать, что многие библиотеки (в том числе и sklearn) умеют это делать. Зачем кожаному мешку напрягаться :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Наша модель\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Подготовим данные для неё\n",
    "# На вход требуется 2D матрица, а у нас только один признак,\n",
    "# и надо превратить его из 1D вектора (n,) в 2D матрицу (n, 1).\n",
    "# Это можно сделать с помощью метода reshape\n",
    "x = data[\"TV\"].values.reshape(-1, 1) \n",
    "y = data[\"Sales\"].values\n",
    "\n",
    "# Обучаем нашу модель\n",
    "reg.fit(x, y)\n",
    "\n",
    "# Коэффициенты\n",
    "print(\"Сдвиг={}\".format(reg.intercept_))\n",
    "print(\"Массив коэффициентов={}\".format(reg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпретируем коэффициенты\n",
    "Что означает коэффициент, связанный с телевидением ($\\beta_1$)?\n",
    "* Дополнительные 1000$, вложенные на в рекламу на телевидении, позволят продажам товара вырасти где-то на 0.047 * 1000 = 47 тысяч единиц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитаем ручками\n",
    "7.032594 + 0.047537*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pd.DataFrame({'TV': [50]})\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нарисуем нашу прямую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмём предсказания для данных, на которых обучались\n",
    "y_pred = reg.predict(x)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сначала выведем истинные данные\n",
    "data.plot(kind='scatter', x='TV', y='Sales')\n",
    "\n",
    "# Теперь рисуем нашу линию\n",
    "plt.plot(x, y_pred, c='red', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем ошибку MSE на обучающей выборке:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(mean_squared_error(y_pred, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используем все признаки\n",
    "\n",
    "Простую линейную регрессию с одним признаком можно легко расширить на случай нескольких признаков:\n",
    "$$y=\\beta_0+\\beta_1x_1+...+\\beta_nx_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А для нашего датасета это будет выглядеть так:\n",
    "$$Sales=\\beta_0+\\beta_1*TV+\\beta_2*radio+\\beta_3*newspaper$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте опять воспользуемся sklearn, чтобы их оценить:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "\n",
    "X = data.drop(\"Sales\", axis=1)\n",
    "y = data[\"Sales\"]\n",
    "\n",
    "# Обучаем нашу модель\n",
    "reg.fit(X, y)\n",
    "\n",
    "# Коэффициенты\n",
    "print(\"Сдвиг={}\".format(reg.intercept_))\n",
    "for column, coef in zip(X.columns, reg.coef_):\n",
    "    print(\"Коэффициент для {}={}\".format(column, coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вес признака отвечает также, как и в предыдущем случае за значимость этого признака. Для газет он вообще отрицательный. Вычислим ошибку на обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X)\n",
    "\n",
    "# Ошибка теперь равна:\n",
    "print(mean_squared_error(y_pred, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка уже меньше, чем при одном признаке, однако измерять ошибку на обучающей выборке неправильно. Помимо истинной зависимости между признаками и целевой переменной, туда могут затесаться случайности, лишние данные и прочие факторы. Если не ограничивать каким-то образом модель (об этом мы узнаем позднее), то модель легко подстраивается под эти шумы. Она начинает показывать очень хорошее качество на обучающей выборке, но когда мы попробуем посмотреть качество на других выборках, то там модель будет показывать себя плохо. Это и есть переобучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"overfit.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому применим кросс-валидацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Многие выбирают k=5 для начала\n",
    "k = 5\n",
    "errors = []\n",
    "\n",
    "X = data.drop(\"Sales\", axis=1)\n",
    "y = data[\"Sales\"]\n",
    "\n",
    "# Размер одной части\n",
    "fold_size = len(X) // k\n",
    "\n",
    "# Мб этот код на семинаре написать?\n",
    "for i in range(k):\n",
    "    # Берём все значения, кроме выбранной части\n",
    "    X_train = X[:i * fold_size].append(X[(i + 1) * fold_size:])\n",
    "    y_train = y[:i * fold_size].append(y[(i + 1) * fold_size:])\n",
    "    \n",
    "    # Берём выбранную часть\n",
    "    X_test = X[i * fold_size:(i + 1) * fold_size]\n",
    "    y_test = y[i * fold_size:(i + 1) * fold_size]\n",
    "    \n",
    "    # На каждой итерации обучаемся отдельно и сохраняем ошибку\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    errors.append(mean_squared_error(y_pred, y_test))\n",
    "    \n",
    "# Выводим ошибку на кросс-валидации\n",
    "print(np.average(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# А можно не париться и попросить sklearn всё сделать за нас\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Берём с отрицательным знаком, т.к. обычно туда передаётся не функция потерь, которую надо минимизировать\n",
    "# А что-то вроде \"функции успеха\", которую надо максимизировать\n",
    "errors = -cross_val_score(LinearRegression(), X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(np.average(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что ошибка больше, чем тогда на обучающей выборке, поэтому есть показания думать, что это переобучение. Отчего оно обычно происходит? Мы берём слишком много лишних признаков или делаем модель слишком сложной для данной задачи. Для решения этой задачи существует регуляризация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регуляризация\n",
    "\n",
    "Регуляризация - это искусстенное занижение всех параметров моделей ($\\beta_0,\\beta_1,...$). Это помогает упростить модель, т.к. низкие значения $\\beta_i$ означают, что модель будет выдавать результаты близкие к прямой (или гиперплоскости, если параметров много). А также зануление некоторых коэффициентов может убрать ненужные признаки из обучения. Однако как всё это сделать так, чтобы не убрать нужные признаки?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на функцию потерь, которую мы минимизируем:\n",
    "$$L(\\beta)=\\sum_{i=1}^{N}(y^{true}_i-y^{pred}_i)^2$$\n",
    "\n",
    "Добавим туда слагаемое, которое поможет нам понизить значения наших $\\beta_i$:\n",
    "$$L(\\beta)=\\sum_{i=1}^{N}(y^{true}_i-y^{pred}_i)^2 + \\lambda \\sum_{i=1}^m\\beta_i^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Действительно, если мы будем понижать нашу функцию потерь $L(\\beta)$, то мы будем минимизировать и второе слагаемое, которое и отвечает за абсолютные величины $\\beta_i$. Осталось указать, что $\\lambda$ это некоторый числовой коэффициент, который позволяет играться между очень сильной и очень слабой регуляризацией. Если он большой, то регуляризация сильная и модель будет более простой, меньше переобучаться, больше недообучаться, и наоброт. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Забыл добавить, что это была L2-регуляризация.\n",
    "L1-регуляризация выглядит так:\n",
    "$$L(\\beta)=\\sum_{i=1}^{N}(y^{true}_i-y^{pred}_i)^2 + \\lambda \\sum_{i=1}^m|\\beta_i|$$\n",
    "Она отличается от L2 тем, что она обнуляет некоторые коэффициенты, а L2 пытается всё уменьшать равномерно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn L1-регуляризация - это Lasso, а L2-регуляризация - это Ridge. Давайте посмотрим, какое качество они нам дадут на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "reg = Lasso().fit(X, y)\n",
    "\n",
    "# Посмотрим на коэффициенты модели\n",
    "# Коэффициенты\n",
    "print(\"Сдвиг={}\".format(reg.intercept_))\n",
    "for column, coef in zip(X.columns, reg.coef_):\n",
    "    print(\"Коэффициент для {}={}\".format(column, coef))\n",
    "print()\n",
    "\n",
    "errors = -cross_val_score(Lasso(), X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(\"Результат={}\".format(np.average(errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что признак с рекламой в газетах модель захотела полностью убрать из выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "reg = Ridge().fit(X, y)\n",
    "\n",
    "# Посмотрим на коэффициенты модели\n",
    "# Коэффициенты\n",
    "print(\"Сдвиг={}\".format(reg.intercept_))\n",
    "for column, coef in zip(X.columns, reg.coef_):\n",
    "    print(\"Коэффициент для {}={}\".format(column, coef))\n",
    "print()\n",
    "\n",
    "errors = -cross_val_score(Ridge(), X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(\"Результат={}\".format(np.average(errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reg.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут модель полностью не зануляла все признаки, а уменьшила их веса некоторых из них, а некоторых увеличила. Но изменения были столь незначительные, что качество не изменилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, качество не сильно улучшилось. Это всё потому что, мы не подбирали параметр параметр lambda (в моделях он называется alpha), а оставили его равным 1.0. Вот тут нам и приходит на помощь кросс-валидация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сначала Lasso. Давайте сначала поступим по тупому, и будем выбирать параметр lambda на обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.arange(0.1, 3.0, 0.2)\n",
    "# Выведем доступные lambda\n",
    "print(\"Все лямбды:\")\n",
    "print(lambdas)\n",
    "\n",
    "# Лямбды и их ошибки на обучающей выборке\n",
    "lambda_errors = []\n",
    "\n",
    "# Проходим по всем лямбдам и записываем ошибки на обучающей выборке\n",
    "for val in lambdas:\n",
    "    reg = Lasso(alpha=val).fit(X, y)\n",
    "    y_pred = reg.predict(X)\n",
    "    # Сохраняем ошибку на обучающей выборке\n",
    "    lambda_errors.append((val, mean_squared_error(y_pred, y)))\n",
    "    print(((val, mean_squared_error(y_pred, y))))\n",
    "    \n",
    "\n",
    "min_val, min_train_error = min(lambda_errors, key=lambda x: x[1])\n",
    "\n",
    "# Вычислим ошибку на кросс-валидации\n",
    "# Лучшая модель\n",
    "best_reg = Lasso(alpha=min_val)\n",
    "cv_error = -np.average(cross_val_score(best_reg, X, y, cv=5, scoring='neg_mean_squared_error'))\n",
    "\n",
    "print(\"\\nОптимальная lambda:\")\n",
    "print(\"Lambda={:.2f}, результат={:.2f}\".format(min_val, cv_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь сделайте так, чтобы сохранялась ошибка не на обучающей выборке, а на кросс-валдиации (cross_val_score) и минимум выбирался из неё. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 балла) Обязательное задание 4:** нарисуйте график зависимости ошибки на тестовом множестве от степени многочлена. При какой степени ошибка минимальна?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 балла) Обязательное задание 5:** Сделайте то же самое для L2-регуляризации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если всё было правильно, то данные манипуляции помогут немного улучшить качество вашей модели. Это поднимет вас на несколько мест в соревнованиях, или вашему работодателю даст побольше прибыли."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основное домашнее задание (6 баллов + гешефт за улучшения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для домашнего задания вы используете другой датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetes.data.csv', sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете приводится информация о пациентах и их состоянии при заболевании диабетом. Описание признаков можно прочитать [здесь](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html). Колонка Y - целевая переменная:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Y'\n",
    "X = data.drop([target], axis=1)\n",
    "y = data[target]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваша задача - провести то же исследование, что и в датасете в самом начале (Sales ~ TV, Radio, Newspaper). В итоге, нужно получить модель линейной регрессии, качество которой надо вывести с помощью cross_val_score с метрикой MSE (тоже самое в общем)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За каждое достойное улучшение качества на cross_val_score будут доп. баллы. Не забудьте описать, что использовали, что получилось и нет, а также попробуйте понять почему. Побольше гуглите. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможные улучшения:\n",
    "* Нормализация данных: вычитаем из каждой колонки её среднее и делим на её дисперсию.\n",
    "* Пробуйте убрать ненужные признаки.\n",
    "* Можно перемножать некоторые признаки.\n",
    "* Погуглите что-то вроде \"improve linear regression\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем, представьте, что вы работаете датасаентистом, получаете 300к долларов, а вам сказали, что нужно как можно лучше уметь предсказывать такие данные."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
